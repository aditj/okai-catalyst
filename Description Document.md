
### **Application Design Document: The "Catalyst" Problem Analysis Skills Assessment**

**1. Vision & Executive Summary**

"Catalyst" is a cutting-edge assessment platform designed for our operational excellence consulting firm to serve our clients in the MSME and MNC sectors. It addresses a critical need for Human Resources and management teams to objectively measure the practical problem analysis skills of their technical staff, particularly managers and team leaders in a manufacturing environment.

Moving beyond traditional psychometric tests, Catalyst uses a dynamic, LLM-powered case study methodology to evaluate a candidate's innate and learned ability to solve real-world operational problems. It specifically targets core competencies like Root Cause Analysis (using frameworks like **$6M$** and **Why-Why Analysis**) and data interpretation, regardless of the individual's formal training history. The platform will generate unique assessments, provide automated, in-depth evaluations, and deliver actionable reports to identify skill gaps and recommend targeted training interventions, fostering a culture of continuous improvement.

**2. Target Audience & Market**

* **Primary Users:** Human Resources (HR) departments, Plant Managers, and Department Heads within manufacturing companies.
* **End-Users (Test Takers):** New and existing managers, team leaders, and process engineers.
* **Target Companies:**
    * **MSMEs (Micro, Small, and Medium Enterprises):** Seeking to upscale their workforce's capabilities without the budget for extensive, one-size-fits-all training programs.
    * **MNCs (Multinational Corporations):** Aiming to standardize skill evaluation across diverse locations and identify high-potential leaders.

**3. Core Features & Modules**

The Catalyst platform will be built around a seamless, interactive, and intelligent user experience.

**3.1. The Dynamic Content Engine (LLM-Powered)**
This is the core of the assessment's fairness and scalability. The LLM will generate unique, realistic manufacturing case studies on-demand.
* **Customizable Parameters:** HR or administrators can define the context of the case study, including:
    * **Industry:** Automotive, Pharmaceuticals, FMCG, etc.
    * **Problem Type:** Quality Defects, Production Delays, Safety Incidents, Cost Overruns.
    * **Data Availability:** Simulating real-world scenarios by providing access to production logs, quality reports, operator feedback, etc.
    * **Complexity Level:** Ranging from single, clear root causes to complex problems with multiple intertwined issues.

**3.2. The User Assessment Interface & Workflow**
The candidate will be guided through a structured, multi-stage problem-solving journey:

* **Stage 1: Problem Briefing:** The user is presented with the dynamically generated case study, outlining a specific operational problem.
* **Stage 2: Information Gathering:** The user can query a system (simulating asking for reports or data) to receive pre-defined information, testing their data-driven approach.
* **Stage 3: Problem Definition:** The user must submit a clear, concise problem statement. The LLM evaluates this for clarity, specificity, and its distinction from mere symptoms.
* **Stage 4: Root Cause Analysis:** Guided by prompts, the user will categorize potential causes (implicitly or explicitly using the **$6M$** framework) and then perform a deep-dive analysis to find the primary root cause (simulating a **Why-Why Analysis**).
* **Stage 5: Solution Proposal & Prioritization:** The user proposes concrete solutions, justifying them based on their analysis and prioritizing them by impact and feasibility.
* **Stage 6: Rationale & Reflection:** The user provides a final summary explaining their thought process, which helps assess their communication and metacognitive skills.

**3.3. The Intelligent Evaluation Engine (LLM-Powered)**
This engine works in the background to provide real-time, objective scoring and analysis.
* **Automated Scoring:** The LLM will use a detailed, pre-defined rubric to score the candidate's text-based inputs at each stage. It will assess the logical consistency of their **Why-Why Analysis**, the comprehensiveness of their **$6M$** categorization, the feasibility of their solutions, and the clarity of their communication.
* **Pattern Recognition:** Across multiple assessments, the LLM will analyze aggregate data to identify common misconceptions, organizational blind spots, and prevalent skill gaps (e.g., "70% of managers struggle to move beyond the second 'Why' in their analysis").

**3.4. Reporting & Analytics Dashboard**
The platform will generate two distinct, high-value reports:

* **For the Candidate (Personal Development Plan):**
    * An overall performance score.
    * A detailed breakdown of strengths and weaknesses across the core competencies.
    * Personalized, constructive feedback generated by the LLM, with specific examples from their own responses.
    * An automated recommendation for a development plan (e.g., "Focus on training for Structured Root Cause Analysis").

* **For HR & Management (Strategic Workforce Insights):**
    * An interactive dashboard showing individual and team-level performance.
    * A clear visualization of organizational skill gaps.
    * Data-driven recommendations for specific group training programs (e.g., "A workshop on 'Data Interpretation for Problem Solving' is recommended for the Production Department").

***

### **Top 4 MVP (Minimum Viable Product) Todos**

This list prioritizes the essential features needed to build a functional prototype that proves the core concept and can be used for initial pilot testing.

**1. Build the Core Case Study & Response Module:**
* **Objective:** Create the foundational user-facing components.
* **To-Do:** Develop a simple web interface where a user can be presented with a *single, hardcoded* manufacturing case study. The interface must include a text input field for the user to write their full analysis (combining problem definition, RCA, and solution) and a "Submit" button. This focuses on the user interaction flow without the initial complexity of dynamic generation.

**2. Develop the Backend Evaluation Endpoint:**
* **Objective:** Create the "magic" of the evaluation.
* **To-Do:** Set up a secure backend service with an API endpoint that receives the user's text response. This service will then call an LLM API (like Google's Gemini API). The prompt sent to the LLM will include the user's text *and* a carefully crafted "system prompt" containing the scoring rubric to evaluate the submission for Problem Definition, Root Cause Analysis logic, and Solution Feasibility, returning a score and a qualitative feedback paragraph.

**3. Implement the Basic Results Page:**
* **Objective:** Close the feedback loop for the user and demonstrate value.
* **To-Do:** Create a simple results page that displays the output from the evaluation endpoint. This page should show the candidate (1) their original submission, (2) the numerical score(s) returned by the LLM, and (3) the verbatim qualitative feedback generated by the LLM.

**4. Integrate LLM for On-the-Fly Case Study Generation:**
* **Objective:** Prove the "dynamic content" concept, which is a key selling point.
* **To-Do:** Replace the hardcoded case study from Todo #1. Create a function in the backend that calls the LLM with a prompt to generate a case study based on a few fixed parameters (e.g., "Generate a case study about a quality defect in an automotive parts factory"). The web interface will then display this newly generated case study to the user, ensuring a unique assessment experience each time the page is loaded.